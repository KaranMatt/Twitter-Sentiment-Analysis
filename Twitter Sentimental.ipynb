{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e97ce8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_df=pd.read_csv('Data/twitter_training.csv')\n",
    "test_df=pd.read_csv('Data/twitter_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5216c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns=['tweet_id','topic','sentiment','text']\n",
    "test_df.columns=['tweet_id','topic','sentiment','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88dd4422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74676</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74681 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id        topic sentiment  \\\n",
       "0          2401  Borderlands  Positive   \n",
       "1          2401  Borderlands  Positive   \n",
       "2          2401  Borderlands  Positive   \n",
       "3          2401  Borderlands  Positive   \n",
       "4          2401  Borderlands  Positive   \n",
       "...         ...          ...       ...   \n",
       "74676      9200       Nvidia  Positive   \n",
       "74677      9200       Nvidia  Positive   \n",
       "74678      9200       Nvidia  Positive   \n",
       "74679      9200       Nvidia  Positive   \n",
       "74680      9200       Nvidia  Positive   \n",
       "\n",
       "                                                    text  \n",
       "0      I am coming to the borders and I will kill you...  \n",
       "1      im getting on borderlands and i will kill you ...  \n",
       "2      im coming on borderlands and i will murder you...  \n",
       "3      im getting on borderlands 2 and i will murder ...  \n",
       "4      im getting into borderlands and i can murder y...  \n",
       "...                                                  ...  \n",
       "74676  Just realized that the Windows partition of my...  \n",
       "74677  Just realized that my Mac window partition is ...  \n",
       "74678  Just realized the windows partition of my Mac ...  \n",
       "74679  Just realized between the windows partition of...  \n",
       "74680  Just like the windows partition of my Mac is l...  \n",
       "\n",
       "[74681 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3b3bdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>352</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8312</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4371</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4433</td>\n",
       "      <td>Google</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6273</td>\n",
       "      <td>FIFA</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hi @EAHelp I’ve had Madeleine McCann in my cel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>4891</td>\n",
       "      <td>GrandTheftAuto(GTA)</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>⭐️ Toronto is the arts and culture capital of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4359</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2652</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Today sucked so it’s time to drink wine n play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>8069</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Bought a fraction of Microsoft today. Small wins.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>6960</td>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Johnson &amp; Johnson to stop selling talc baby po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id                topic   sentiment  \\\n",
       "0         352               Amazon     Neutral   \n",
       "1        8312            Microsoft    Negative   \n",
       "2        4371                CS-GO    Negative   \n",
       "3        4433               Google     Neutral   \n",
       "4        6273                 FIFA    Negative   \n",
       "..        ...                  ...         ...   \n",
       "994      4891  GrandTheftAuto(GTA)  Irrelevant   \n",
       "995      4359                CS-GO  Irrelevant   \n",
       "996      2652          Borderlands    Positive   \n",
       "997      8069            Microsoft    Positive   \n",
       "998      6960      johnson&johnson     Neutral   \n",
       "\n",
       "                                                  text  \n",
       "0    BBC News - Amazon boss Jeff Bezos rejects clai...  \n",
       "1    @Microsoft Why do I pay for WORD when it funct...  \n",
       "2    CSGO matchmaking is so full of closet hacking,...  \n",
       "3    Now the President is slapping Americans in the...  \n",
       "4    Hi @EAHelp I’ve had Madeleine McCann in my cel...  \n",
       "..                                                 ...  \n",
       "994  ⭐️ Toronto is the arts and culture capital of ...  \n",
       "995  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...  \n",
       "996  Today sucked so it’s time to drink wine n play...  \n",
       "997  Bought a fraction of Microsoft today. Small wins.  \n",
       "998  Johnson & Johnson to stop selling talc baby po...  \n",
       "\n",
       "[999 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f6436c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74681 entries, 0 to 74680\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet_id   74681 non-null  int64 \n",
      " 1   topic      74681 non-null  object\n",
      " 2   sentiment  74681 non-null  object\n",
      " 3   text       73995 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27a379a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999 entries, 0 to 998\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet_id   999 non-null    int64 \n",
      " 1   topic      999 non-null    object\n",
      " 2   sentiment  999 non-null    object\n",
      " 3   text       999 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 31.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe21f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=['text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c4bd9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>[I, am, coming, to, the, borders, and, I, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>[im, getting, on, borderlands, and, i, will, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>[im, coming, on, borderlands, and, i, will, mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>[im, getting, on, borderlands, 2, and, i, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "      <td>[im, getting, into, borderlands, and, i, can, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74676</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "      <td>[Just, realized, that, the, Windows, partition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "      <td>[Just, realized, that, my, Mac, window, partit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "      <td>[Just, realized, the, windows, partition, of, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "      <td>[Just, realized, between, the, windows, partit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "      <td>[Just, like, the, windows, partition, of, my, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73995 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id        topic sentiment  \\\n",
       "0          2401  Borderlands  Positive   \n",
       "1          2401  Borderlands  Positive   \n",
       "2          2401  Borderlands  Positive   \n",
       "3          2401  Borderlands  Positive   \n",
       "4          2401  Borderlands  Positive   \n",
       "...         ...          ...       ...   \n",
       "74676      9200       Nvidia  Positive   \n",
       "74677      9200       Nvidia  Positive   \n",
       "74678      9200       Nvidia  Positive   \n",
       "74679      9200       Nvidia  Positive   \n",
       "74680      9200       Nvidia  Positive   \n",
       "\n",
       "                                                    text  \\\n",
       "0      I am coming to the borders and I will kill you...   \n",
       "1      im getting on borderlands and i will kill you ...   \n",
       "2      im coming on borderlands and i will murder you...   \n",
       "3      im getting on borderlands 2 and i will murder ...   \n",
       "4      im getting into borderlands and i can murder y...   \n",
       "...                                                  ...   \n",
       "74676  Just realized that the Windows partition of my...   \n",
       "74677  Just realized that my Mac window partition is ...   \n",
       "74678  Just realized the windows partition of my Mac ...   \n",
       "74679  Just realized between the windows partition of...   \n",
       "74680  Just like the windows partition of my Mac is l...   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [I, am, coming, to, the, borders, and, I, will...  \n",
       "1      [im, getting, on, borderlands, and, i, will, k...  \n",
       "2      [im, coming, on, borderlands, and, i, will, mu...  \n",
       "3      [im, getting, on, borderlands, 2, and, i, will...  \n",
       "4      [im, getting, into, borderlands, and, i, can, ...  \n",
       "...                                                  ...  \n",
       "74676  [Just, realized, that, the, Windows, partition...  \n",
       "74677  [Just, realized, that, my, Mac, window, partit...  \n",
       "74678  [Just, realized, the, windows, partition, of, ...  \n",
       "74679  [Just, realized, between, the, windows, partit...  \n",
       "74680  [Just, like, the, windows, partition, of, my, ...  \n",
       "\n",
       "[73995 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_token=TweetTokenizer()\n",
    "train_df['tokens']=train_df['text'].apply(tweet_token.tokenize)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7370c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>352</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "      <td>[BBC, News, -, Amazon, boss, Jeff, Bezos, reje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8312</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "      <td>[@Microsoft, Why, do, I, pay, for, WORD, when,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4371</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "      <td>[CSGO, matchmaking, is, so, full, of, closet, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4433</td>\n",
       "      <td>Google</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "      <td>[Now, the, President, is, slapping, Americans,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6273</td>\n",
       "      <td>FIFA</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hi @EAHelp I’ve had Madeleine McCann in my cel...</td>\n",
       "      <td>[Hi, @EAHelp, I, ’, ve, had, Madeleine, McCann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>4891</td>\n",
       "      <td>GrandTheftAuto(GTA)</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>⭐️ Toronto is the arts and culture capital of ...</td>\n",
       "      <td>[⭐, ️, Toronto, is, the, arts, and, culture, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4359</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...</td>\n",
       "      <td>[tHIS, IS, ACTUALLY, A, GOOD, MOVE, TOT, BRING...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2652</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Today sucked so it’s time to drink wine n play...</td>\n",
       "      <td>[Today, sucked, so, it, ’, s, time, to, drink,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>8069</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Bought a fraction of Microsoft today. Small wins.</td>\n",
       "      <td>[Bought, a, fraction, of, Microsoft, today, .,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>6960</td>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Johnson &amp; Johnson to stop selling talc baby po...</td>\n",
       "      <td>[Johnson, &amp;, Johnson, to, stop, selling, talc,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id                topic   sentiment  \\\n",
       "0         352               Amazon     Neutral   \n",
       "1        8312            Microsoft    Negative   \n",
       "2        4371                CS-GO    Negative   \n",
       "3        4433               Google     Neutral   \n",
       "4        6273                 FIFA    Negative   \n",
       "..        ...                  ...         ...   \n",
       "994      4891  GrandTheftAuto(GTA)  Irrelevant   \n",
       "995      4359                CS-GO  Irrelevant   \n",
       "996      2652          Borderlands    Positive   \n",
       "997      8069            Microsoft    Positive   \n",
       "998      6960      johnson&johnson     Neutral   \n",
       "\n",
       "                                                  text  \\\n",
       "0    BBC News - Amazon boss Jeff Bezos rejects clai...   \n",
       "1    @Microsoft Why do I pay for WORD when it funct...   \n",
       "2    CSGO matchmaking is so full of closet hacking,...   \n",
       "3    Now the President is slapping Americans in the...   \n",
       "4    Hi @EAHelp I’ve had Madeleine McCann in my cel...   \n",
       "..                                                 ...   \n",
       "994  ⭐️ Toronto is the arts and culture capital of ...   \n",
       "995  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...   \n",
       "996  Today sucked so it’s time to drink wine n play...   \n",
       "997  Bought a fraction of Microsoft today. Small wins.   \n",
       "998  Johnson & Johnson to stop selling talc baby po...   \n",
       "\n",
       "                                                tokens  \n",
       "0    [BBC, News, -, Amazon, boss, Jeff, Bezos, reje...  \n",
       "1    [@Microsoft, Why, do, I, pay, for, WORD, when,...  \n",
       "2    [CSGO, matchmaking, is, so, full, of, closet, ...  \n",
       "3    [Now, the, President, is, slapping, Americans,...  \n",
       "4    [Hi, @EAHelp, I, ’, ve, had, Madeleine, McCann...  \n",
       "..                                                 ...  \n",
       "994  [⭐, ️, Toronto, is, the, arts, and, culture, c...  \n",
       "995  [tHIS, IS, ACTUALLY, A, GOOD, MOVE, TOT, BRING...  \n",
       "996  [Today, sucked, so, it, ’, s, time, to, drink,...  \n",
       "997  [Bought, a, fraction, of, Microsoft, today, .,...  \n",
       "998  [Johnson, &, Johnson, to, stop, selling, talc,...  \n",
       "\n",
       "[999 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['tokens']=test_df['text'].apply(tweet_token.tokenize)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30ea0165",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['lower_tokens']=train_df['tokens'].apply(lambda tokens:[token.lower() for token in tokens])\n",
    "test_df['lower_tokens']=test_df['tokens'].apply(lambda tokens:[token.lower() for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef70f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "train_df['no_stopwords']=train_df['lower_tokens'].apply(lambda tokens:[token for token in tokens if token not in stop_words])\n",
    "test_df['no_stopwords']=test_df['lower_tokens'].apply(lambda tokens:[token for token in tokens if token not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "922567ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lower_tokens</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>[I, am, coming, to, the, borders, and, I, will...</td>\n",
       "      <td>[i, am, coming, to, the, borders, and, i, will...</td>\n",
       "      <td>[coming, borders, kill, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>[im, getting, on, borderlands, and, i, will, k...</td>\n",
       "      <td>[im, getting, on, borderlands, and, i, will, k...</td>\n",
       "      <td>[im, getting, borderlands, kill, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>[im, coming, on, borderlands, and, i, will, mu...</td>\n",
       "      <td>[im, coming, on, borderlands, and, i, will, mu...</td>\n",
       "      <td>[im, coming, borderlands, murder, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>[im, getting, on, borderlands, 2, and, i, will...</td>\n",
       "      <td>[im, getting, on, borderlands, 2, and, i, will...</td>\n",
       "      <td>[im, getting, borderlands, 2, murder, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "      <td>[im, getting, into, borderlands, and, i, can, ...</td>\n",
       "      <td>[im, getting, into, borderlands, and, i, can, ...</td>\n",
       "      <td>[im, getting, borderlands, murder, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74676</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "      <td>[Just, realized, that, the, Windows, partition...</td>\n",
       "      <td>[just, realized, that, the, windows, partition...</td>\n",
       "      <td>[realized, windows, partition, mac, like, 6, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "      <td>[Just, realized, that, my, Mac, window, partit...</td>\n",
       "      <td>[just, realized, that, my, mac, window, partit...</td>\n",
       "      <td>[realized, mac, window, partition, 6, years, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "      <td>[Just, realized, the, windows, partition, of, ...</td>\n",
       "      <td>[just, realized, the, windows, partition, of, ...</td>\n",
       "      <td>[realized, windows, partition, mac, 6, years, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "      <td>[Just, realized, between, the, windows, partit...</td>\n",
       "      <td>[just, realized, between, the, windows, partit...</td>\n",
       "      <td>[realized, windows, partition, mac, like, 6, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "      <td>[Just, like, the, windows, partition, of, my, ...</td>\n",
       "      <td>[just, like, the, windows, partition, of, my, ...</td>\n",
       "      <td>[like, windows, partition, mac, like, 6, years...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73995 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id        topic sentiment  \\\n",
       "0          2401  Borderlands  Positive   \n",
       "1          2401  Borderlands  Positive   \n",
       "2          2401  Borderlands  Positive   \n",
       "3          2401  Borderlands  Positive   \n",
       "4          2401  Borderlands  Positive   \n",
       "...         ...          ...       ...   \n",
       "74676      9200       Nvidia  Positive   \n",
       "74677      9200       Nvidia  Positive   \n",
       "74678      9200       Nvidia  Positive   \n",
       "74679      9200       Nvidia  Positive   \n",
       "74680      9200       Nvidia  Positive   \n",
       "\n",
       "                                                    text  \\\n",
       "0      I am coming to the borders and I will kill you...   \n",
       "1      im getting on borderlands and i will kill you ...   \n",
       "2      im coming on borderlands and i will murder you...   \n",
       "3      im getting on borderlands 2 and i will murder ...   \n",
       "4      im getting into borderlands and i can murder y...   \n",
       "...                                                  ...   \n",
       "74676  Just realized that the Windows partition of my...   \n",
       "74677  Just realized that my Mac window partition is ...   \n",
       "74678  Just realized the windows partition of my Mac ...   \n",
       "74679  Just realized between the windows partition of...   \n",
       "74680  Just like the windows partition of my Mac is l...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [I, am, coming, to, the, borders, and, I, will...   \n",
       "1      [im, getting, on, borderlands, and, i, will, k...   \n",
       "2      [im, coming, on, borderlands, and, i, will, mu...   \n",
       "3      [im, getting, on, borderlands, 2, and, i, will...   \n",
       "4      [im, getting, into, borderlands, and, i, can, ...   \n",
       "...                                                  ...   \n",
       "74676  [Just, realized, that, the, Windows, partition...   \n",
       "74677  [Just, realized, that, my, Mac, window, partit...   \n",
       "74678  [Just, realized, the, windows, partition, of, ...   \n",
       "74679  [Just, realized, between, the, windows, partit...   \n",
       "74680  [Just, like, the, windows, partition, of, my, ...   \n",
       "\n",
       "                                            lower_tokens  \\\n",
       "0      [i, am, coming, to, the, borders, and, i, will...   \n",
       "1      [im, getting, on, borderlands, and, i, will, k...   \n",
       "2      [im, coming, on, borderlands, and, i, will, mu...   \n",
       "3      [im, getting, on, borderlands, 2, and, i, will...   \n",
       "4      [im, getting, into, borderlands, and, i, can, ...   \n",
       "...                                                  ...   \n",
       "74676  [just, realized, that, the, windows, partition...   \n",
       "74677  [just, realized, that, my, mac, window, partit...   \n",
       "74678  [just, realized, the, windows, partition, of, ...   \n",
       "74679  [just, realized, between, the, windows, partit...   \n",
       "74680  [just, like, the, windows, partition, of, my, ...   \n",
       "\n",
       "                                            no_stopwords  \n",
       "0                             [coming, borders, kill, ,]  \n",
       "1                    [im, getting, borderlands, kill, ,]  \n",
       "2                   [im, coming, borderlands, murder, ,]  \n",
       "3               [im, getting, borderlands, 2, murder, ,]  \n",
       "4                  [im, getting, borderlands, murder, ,]  \n",
       "...                                                  ...  \n",
       "74676  [realized, windows, partition, mac, like, 6, y...  \n",
       "74677  [realized, mac, window, partition, 6, years, b...  \n",
       "74678  [realized, windows, partition, mac, 6, years, ...  \n",
       "74679  [realized, windows, partition, mac, like, 6, y...  \n",
       "74680  [like, windows, partition, mac, like, 6, years...  \n",
       "\n",
       "[73995 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de62f37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lower_tokens</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>[I, am, coming, to, the, borders, and, I, will...</td>\n",
       "      <td>[i, am, coming, to, the, borders, and, i, will...</td>\n",
       "      <td>[coming, borders, kill, ,]</td>\n",
       "      <td>[come, border, kill, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>[im, getting, on, borderlands, and, i, will, k...</td>\n",
       "      <td>[im, getting, on, borderlands, and, i, will, k...</td>\n",
       "      <td>[im, getting, borderlands, kill, ,]</td>\n",
       "      <td>[im, get, borderlands, kill, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>[im, coming, on, borderlands, and, i, will, mu...</td>\n",
       "      <td>[im, coming, on, borderlands, and, i, will, mu...</td>\n",
       "      <td>[im, coming, borderlands, murder, ,]</td>\n",
       "      <td>[im, come, borderlands, murder, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>[im, getting, on, borderlands, 2, and, i, will...</td>\n",
       "      <td>[im, getting, on, borderlands, 2, and, i, will...</td>\n",
       "      <td>[im, getting, borderlands, 2, murder, ,]</td>\n",
       "      <td>[im, get, borderlands, 2, murder, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "      <td>[im, getting, into, borderlands, and, i, can, ...</td>\n",
       "      <td>[im, getting, into, borderlands, and, i, can, ...</td>\n",
       "      <td>[im, getting, borderlands, murder, ,]</td>\n",
       "      <td>[im, get, borderlands, murder, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74676</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "      <td>[Just, realized, that, the, Windows, partition...</td>\n",
       "      <td>[just, realized, that, the, windows, partition...</td>\n",
       "      <td>[realized, windows, partition, mac, like, 6, y...</td>\n",
       "      <td>[realize, windows, partition, mac, like, 6, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "      <td>[Just, realized, that, my, Mac, window, partit...</td>\n",
       "      <td>[just, realized, that, my, mac, window, partit...</td>\n",
       "      <td>[realized, mac, window, partition, 6, years, b...</td>\n",
       "      <td>[realize, mac, window, partition, 6, years, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "      <td>[Just, realized, the, windows, partition, of, ...</td>\n",
       "      <td>[just, realized, the, windows, partition, of, ...</td>\n",
       "      <td>[realized, windows, partition, mac, 6, years, ...</td>\n",
       "      <td>[realize, windows, partition, mac, 6, years, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "      <td>[Just, realized, between, the, windows, partit...</td>\n",
       "      <td>[just, realized, between, the, windows, partit...</td>\n",
       "      <td>[realized, windows, partition, mac, like, 6, y...</td>\n",
       "      <td>[realize, windows, partition, mac, like, 6, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "      <td>[Just, like, the, windows, partition, of, my, ...</td>\n",
       "      <td>[just, like, the, windows, partition, of, my, ...</td>\n",
       "      <td>[like, windows, partition, mac, like, 6, years...</td>\n",
       "      <td>[like, windows, partition, mac, like, 6, years...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73995 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id        topic sentiment  \\\n",
       "0          2401  Borderlands  Positive   \n",
       "1          2401  Borderlands  Positive   \n",
       "2          2401  Borderlands  Positive   \n",
       "3          2401  Borderlands  Positive   \n",
       "4          2401  Borderlands  Positive   \n",
       "...         ...          ...       ...   \n",
       "74676      9200       Nvidia  Positive   \n",
       "74677      9200       Nvidia  Positive   \n",
       "74678      9200       Nvidia  Positive   \n",
       "74679      9200       Nvidia  Positive   \n",
       "74680      9200       Nvidia  Positive   \n",
       "\n",
       "                                                    text  \\\n",
       "0      I am coming to the borders and I will kill you...   \n",
       "1      im getting on borderlands and i will kill you ...   \n",
       "2      im coming on borderlands and i will murder you...   \n",
       "3      im getting on borderlands 2 and i will murder ...   \n",
       "4      im getting into borderlands and i can murder y...   \n",
       "...                                                  ...   \n",
       "74676  Just realized that the Windows partition of my...   \n",
       "74677  Just realized that my Mac window partition is ...   \n",
       "74678  Just realized the windows partition of my Mac ...   \n",
       "74679  Just realized between the windows partition of...   \n",
       "74680  Just like the windows partition of my Mac is l...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [I, am, coming, to, the, borders, and, I, will...   \n",
       "1      [im, getting, on, borderlands, and, i, will, k...   \n",
       "2      [im, coming, on, borderlands, and, i, will, mu...   \n",
       "3      [im, getting, on, borderlands, 2, and, i, will...   \n",
       "4      [im, getting, into, borderlands, and, i, can, ...   \n",
       "...                                                  ...   \n",
       "74676  [Just, realized, that, the, Windows, partition...   \n",
       "74677  [Just, realized, that, my, Mac, window, partit...   \n",
       "74678  [Just, realized, the, windows, partition, of, ...   \n",
       "74679  [Just, realized, between, the, windows, partit...   \n",
       "74680  [Just, like, the, windows, partition, of, my, ...   \n",
       "\n",
       "                                            lower_tokens  \\\n",
       "0      [i, am, coming, to, the, borders, and, i, will...   \n",
       "1      [im, getting, on, borderlands, and, i, will, k...   \n",
       "2      [im, coming, on, borderlands, and, i, will, mu...   \n",
       "3      [im, getting, on, borderlands, 2, and, i, will...   \n",
       "4      [im, getting, into, borderlands, and, i, can, ...   \n",
       "...                                                  ...   \n",
       "74676  [just, realized, that, the, windows, partition...   \n",
       "74677  [just, realized, that, my, mac, window, partit...   \n",
       "74678  [just, realized, the, windows, partition, of, ...   \n",
       "74679  [just, realized, between, the, windows, partit...   \n",
       "74680  [just, like, the, windows, partition, of, my, ...   \n",
       "\n",
       "                                            no_stopwords  \\\n",
       "0                             [coming, borders, kill, ,]   \n",
       "1                    [im, getting, borderlands, kill, ,]   \n",
       "2                   [im, coming, borderlands, murder, ,]   \n",
       "3               [im, getting, borderlands, 2, murder, ,]   \n",
       "4                  [im, getting, borderlands, murder, ,]   \n",
       "...                                                  ...   \n",
       "74676  [realized, windows, partition, mac, like, 6, y...   \n",
       "74677  [realized, mac, window, partition, 6, years, b...   \n",
       "74678  [realized, windows, partition, mac, 6, years, ...   \n",
       "74679  [realized, windows, partition, mac, like, 6, y...   \n",
       "74680  [like, windows, partition, mac, like, 6, years...   \n",
       "\n",
       "                                       lemmatized_tokens  \n",
       "0                                [come, border, kill, ,]  \n",
       "1                        [im, get, borderlands, kill, ,]  \n",
       "2                     [im, come, borderlands, murder, ,]  \n",
       "3                   [im, get, borderlands, 2, murder, ,]  \n",
       "4                      [im, get, borderlands, murder, ,]  \n",
       "...                                                  ...  \n",
       "74676  [realize, windows, partition, mac, like, 6, ye...  \n",
       "74677  [realize, mac, window, partition, 6, years, be...  \n",
       "74678  [realize, windows, partition, mac, 6, years, b...  \n",
       "74679  [realize, windows, partition, mac, like, 6, ye...  \n",
       "74680  [like, windows, partition, mac, like, 6, years...  \n",
       "\n",
       "[73995 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "train_df['lemmatized_tokens']=train_df['no_stopwords'].apply(lambda tokens:[lemmatizer.lemmatize(token,pos='v') for token in tokens])\n",
    "test_df['lemmatized_tokens']=test_df['no_stopwords'].apply(lambda tokens:[lemmatizer.lemmatize(token,pos='v') for token in tokens])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8804292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cleaned_tokens']=train_df['lemmatized_tokens'].apply(lambda tokens:[token for token in tokens if token.isalnum()])\n",
    "test_df['cleaned_tokens']=test_df['lemmatized_tokens'].apply(lambda tokens:[token for token in tokens if token.isalnum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9971dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['processed_text']=train_df['cleaned_tokens'].apply(lambda tokens:' '.join(tokens))\n",
    "test_df['processed_text']=test_df['cleaned_tokens'].apply(lambda tokens:' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1678a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_idf=TfidfVectorizer()\n",
    "train_tfidf=tf_idf.fit_transform(train_df['processed_text'])\n",
    "test_tfidf=tf_idf.transform(test_df['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab35b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=train_df['sentiment']\n",
    "test_label=test_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d80791ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37be036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "def model_evaluate(model):\n",
    "    train_preds=model.predict(train_tfidf)\n",
    "    test_preds=model.predict(test_tfidf)\n",
    "    train_acc=accuracy_score(train_label,train_preds)\n",
    "    test_acc=accuracy_score(test_label,test_preds)\n",
    "    train_f1=f1_score(train_label,train_preds,average='weighted')\n",
    "    test_f1=f1_score(test_label,test_preds,average='weighted')\n",
    "    print(f'Accuracy Score: Train ==> {train_acc} and Test {test_acc}')\n",
    "    print(f'F1 Score: Train ==> {train_f1} and Test {test_f1}')\n",
    "    mlflow.log_metric('Train_Accuracy',train_acc)\n",
    "    mlflow.log_metric('Train_F1',train_f1)\n",
    "    mlflow.log_metric('Test_Accuracy',test_acc)\n",
    "    mlflow.log_metric('Test_F1',test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd2a33c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/KM/Coding%21%21%21/vs%20code/NLP/Twitter%20Sentimental%20Analysis/mlruns/735038141065724645', creation_time=1760998044011, experiment_id='735038141065724645', last_update_time=1760998044011, lifecycle_stage='active', name='Twitter Sentiment Analysis', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment('Twitter Sentiment Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6c79cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KARAN MATTOO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2025/10/21 04:02:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: Train ==> 0.8110007432934657 and Test 0.8678678678678678\n",
      "F1 Score: Train ==> 0.8105598143494591 and Test 0.8677638738277708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/21 04:02:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "with mlflow.start_run(run_name='Logistic Regression'):\n",
    "    model_log=LogisticRegression()\n",
    "    model_log.fit(train_tfidf,train_label)\n",
    "    mlflow.log_params(model_log.get_params())\n",
    "    model_evaluate(model_log)\n",
    "    mlflow.sklearn.log_model(model_log,'Logistic Reg Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5eb0b258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/21 04:06:15 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: Train ==> 0.7464423271842692 and Test 0.7707707707707707\n",
      "F1 Score: Train ==> 0.751682016036206 and Test 0.7769349341661386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/21 04:06:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "with mlflow.start_run(run_name='Decision Tree'):\n",
    "    model_tree=DecisionTreeClassifier(max_depth=85,random_state=42)\n",
    "    model_tree.fit(train_tfidf,train_label)\n",
    "    mlflow.log_params(model_tree.get_params())\n",
    "    model_evaluate(model_tree)\n",
    "    mlflow.sklearn.log_model(model_tree,'dt_model v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e88dc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/21 04:08:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: Train ==> 0.9522670450706129 and Test 0.9619619619619619\n",
      "F1 Score: Train ==> 0.9527112015080388 and Test 0.9620350038564137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/21 04:08:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "with mlflow.start_run(run_name='Random Forest'):\n",
    "    model_forest=RandomForestClassifier(n_jobs=-1,n_estimators=120,max_depth=225,random_state=42)\n",
    "    model_forest.fit(train_tfidf,train_label)\n",
    "    mlflow.log_params(model_forest.get_params())\n",
    "    model_evaluate(model_forest)\n",
    "    mlflow.sklearn.log_model(model_forest,'rf_model v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57e37640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Models/rf.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(model_forest,'Models/rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af031a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Neutral', 'Negative', 'Irrelevant'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee26588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_map={'Positive':0,'Neutral':1,'Negative':2,'Irrelevant':3}\n",
    "train_df['code']=train_df['sentiment'].map(code_map)\n",
    "test_df['code']=test_df['sentiment'].map(code_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44a68f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs=train_df['text'].to_numpy()\n",
    "test_inputs=test_df['text'].to_numpy()\n",
    "train_target=train_df['code'].to_numpy()\n",
    "test_target=test_df['code'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2e7e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization,Embedding,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "082330ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer=TextVectorization(max_tokens=None,ngrams=None,output_mode='int',split='whitespace',\n",
    "                                  standardize='lower_and_strip_punctuation',output_sequence_length=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "476c9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(i.split()) for i in train_inputs])/len(train_inputs)\n",
    "max_length=20\n",
    "max_vocab=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebaabd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer=TextVectorization(max_tokens=max_vocab,output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23cb1c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5aa600fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed=Embedding(input_dim=max_vocab,output_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b60df0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Neutral', 'Negative', 'Irrelevant'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "819d527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,GRU,LSTM,Bidirectional,Input\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9cd469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_eval(model):\n",
    "    train_results=model.evaluate(train_inputs,tf.one_hot(train_target,depth=4))\n",
    "    test_results=model.evaluate(test_inputs,tf.one_hot(test_target,depth=4))\n",
    "    print(f'Train_Metrics: {train_results}')\n",
    "    print(f'Test_Metrics: {test_results}')\n",
    "    train_acc=train_results[1]\n",
    "    test_acc=test_results[1]\n",
    "    train_prec=train_results[2]\n",
    "    test_prec=test_results[2]\n",
    "    train_rec=train_results[3]\n",
    "    test_rec=test_results[3]\n",
    "    mlflow.log_metric('Train_Accuracy',train_acc)\n",
    "    mlflow.log_metric('Test_Accuracy',test_acc)\n",
    "    mlflow.log_metric('Train_Precision',train_prec)\n",
    "    mlflow.log_metric('Test_Precision',test_prec)\n",
    "    mlflow.log_metric('Train_Recall',train_rec)\n",
    "    mlflow.log_metric('Test_Recall',test_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eeee007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.6389 - loss: 0.8890 - precision: 0.7642 - recall: 0.5082 - val_accuracy: 0.8729 - val_loss: 0.3918 - val_precision: 0.8956 - val_recall: 0.8328\n",
      "Epoch 2/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.8194 - loss: 0.4876 - precision: 0.8698 - recall: 0.7791 - val_accuracy: 0.9129 - val_loss: 0.2710 - val_precision: 0.9364 - val_recall: 0.8989\n",
      "Epoch 3/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.8737 - loss: 0.3410 - precision: 0.9139 - recall: 0.8453 - val_accuracy: 0.9209 - val_loss: 0.2569 - val_precision: 0.9315 - val_recall: 0.9119\n",
      "Epoch 4/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9001 - loss: 0.2662 - precision: 0.9356 - recall: 0.8772 - val_accuracy: 0.9339 - val_loss: 0.2379 - val_precision: 0.9466 - val_recall: 0.9219\n",
      "Epoch 5/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9177 - loss: 0.2184 - precision: 0.9503 - recall: 0.8979 - val_accuracy: 0.9279 - val_loss: 0.2425 - val_precision: 0.9407 - val_recall: 0.9209\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9383 - loss: 0.1654 - precision: 0.9689 - recall: 0.9195\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9279 - loss: 0.2425 - precision: 0.9407 - recall: 0.9209\n",
      "Train_Metrics: [0.165366068482399, 0.9383471608161926, 0.9688585996627808, 0.9195351004600525]\n",
      "Test_Metrics: [0.24250482022762299, 0.9279279112815857, 0.9406952857971191, 0.9209209084510803]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with mlflow.start_run(run_name='GRU'):\n",
    "    inputs=Input(shape=(1,),dtype=tf.string)\n",
    "    x=text_vectorizer(inputs)\n",
    "    x=embed(x)\n",
    "    x=GRU(48,activation='tanh',return_sequences=True)(x)\n",
    "    x=GRU(48,activation='tanh')(x)\n",
    "    outputs=Dense(4,activation='softmax')(x)\n",
    "    model_1=Model(inputs,outputs)\n",
    "    model_1.compile(loss=CategoricalCrossentropy(),optimizer=Adam(),metrics=['accuracy','precision','recall'])\n",
    "    model_1.fit(train_inputs,tf.one_hot(train_target,depth=4),epochs=5,validation_data=(test_inputs,tf.one_hot(test_target,depth=4)))\n",
    "\n",
    "    mlflow.log_params({'epochs':5,'loss':'CategoricalCrossentropy','optimizer':'Adam','learning_rate':'default',\n",
    "                       'model_type':'GRU','activation':'tanh','metrics':'Accuracy,Precison,Recall'})\n",
    "    dl_eval(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a93d3c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8401 - loss: 0.4173 - precision: 0.8945 - recall: 0.7974 - val_accuracy: 0.9199 - val_loss: 0.2420 - val_precision: 0.9295 - val_recall: 0.9109\n",
      "Epoch 2/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.9113 - loss: 0.2343 - precision: 0.9446 - recall: 0.8903 - val_accuracy: 0.9399 - val_loss: 0.2121 - val_precision: 0.9501 - val_recall: 0.9329\n",
      "Epoch 3/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.9262 - loss: 0.1913 - precision: 0.9582 - recall: 0.9080 - val_accuracy: 0.9389 - val_loss: 0.2350 - val_precision: 0.9440 - val_recall: 0.9289\n",
      "Epoch 4/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.9350 - loss: 0.1683 - precision: 0.9644 - recall: 0.9178 - val_accuracy: 0.9369 - val_loss: 0.2538 - val_precision: 0.9490 - val_recall: 0.9319\n",
      "Epoch 5/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9423 - loss: 0.1468 - precision: 0.9708 - recall: 0.9265 - val_accuracy: 0.9409 - val_loss: 0.2484 - val_precision: 0.9502 - val_recall: 0.9359\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1210 - precision: 0.9820 - recall: 0.9354\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9409 - loss: 0.2484 - precision: 0.9502 - recall: 0.9359\n",
      "Train_Metrics: [0.12101458758115768, 0.9523211121559143, 0.9819678068161011, 0.9353875517845154]\n",
      "Test_Metrics: [0.24839822947978973, 0.9409409165382385, 0.9502032399177551, 0.935935914516449]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with mlflow.start_run(run_name='LSTM'):\n",
    "    inputs=Input(shape=(1,),dtype=tf.string)\n",
    "    x=text_vectorizer(inputs)\n",
    "    x=embed(x)\n",
    "    x=LSTM(48,activation='tanh',return_sequences=True)(x)\n",
    "    x=LSTM(48,activation='tanh')(x)\n",
    "    outputs=Dense(4,activation='softmax')(x)\n",
    "    model_2=Model(inputs,outputs)\n",
    "    model_2.compile(loss=CategoricalCrossentropy(),optimizer=Adam(),metrics=['accuracy','precision','recall'])\n",
    "    model_2.fit(train_inputs,tf.one_hot(train_target,depth=4),epochs=5,validation_data=(test_inputs,tf.one_hot(test_target,depth=4)))\n",
    "\n",
    "    mlflow.log_params({'epochs':5,'loss':'CategoricalCrossentropy','optimizer':'Adam','learning_rate':'default',\n",
    "                       'model_type':'LSTM','activation':'tanh','metrics':'Accuracy,Precison,Recall','Layers':2})\n",
    "    dl_eval(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c85ee35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f20f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hfdbgf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2465d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.8680 - loss: 0.3422 - precision: 0.9182 - recall: 0.8292 - val_accuracy: 0.9279 - val_loss: 0.2507 - val_precision: 0.9367 - val_recall: 0.9179\n",
      "Epoch 2/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9336 - loss: 0.1722 - precision: 0.9632 - recall: 0.9173 - val_accuracy: 0.9359 - val_loss: 0.2428 - val_precision: 0.9431 - val_recall: 0.9299\n",
      "Epoch 3/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9424 - loss: 0.1458 - precision: 0.9707 - recall: 0.9267 - val_accuracy: 0.9349 - val_loss: 0.2416 - val_precision: 0.9451 - val_recall: 0.9309\n",
      "Epoch 4/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9489 - loss: 0.1291 - precision: 0.9757 - recall: 0.9339 - val_accuracy: 0.9389 - val_loss: 0.2546 - val_precision: 0.9461 - val_recall: 0.9319\n",
      "Epoch 5/5\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9523 - loss: 0.1183 - precision: 0.9781 - recall: 0.9387 - val_accuracy: 0.9339 - val_loss: 0.2927 - val_precision: 0.9430 - val_recall: 0.9279\n",
      "\u001b[1m2313/2313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1023 - precision: 0.9852 - recall: 0.9439\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9339 - loss: 0.2927 - precision: 0.9430 - recall: 0.9279\n",
      "Train_Metrics: [0.10230334848165512, 0.9591999650001526, 0.9851759076118469, 0.943942129611969]\n",
      "Test_Metrics: [0.2927373945713043, 0.9339339137077332, 0.9430315494537354, 0.9279279112815857]\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='Bi_LSTM'):\n",
    "    inputs=Input(shape=(1,),dtype=tf.string)\n",
    "    x=text_vectorizer(inputs)\n",
    "    x=embed(x)\n",
    "    x=Bidirectional(LSTM(32,activation='tanh',return_sequences=True))(x)\n",
    "    x=Bidirectional(LSTM(32,activation='tanh'))(x)\n",
    "    outputs=Dense(4,activation='softmax')(x)\n",
    "    model_3=Model(inputs,outputs)\n",
    "    model_3.compile(loss=CategoricalCrossentropy(),optimizer=Adam(),metrics=['accuracy','precision','recall'])\n",
    "    model_3.fit(train_inputs,tf.one_hot(train_target,depth=4),epochs=5,validation_data=(test_inputs,tf.one_hot(test_target,depth=4)))\n",
    "\n",
    "    mlflow.log_params({'epochs':5,'loss':'CategoricalCrossentropy','optimizer':'Adam','learning_rate':'default',\n",
    "                       'model_type':'Bi-LSTM','activation':'tanh','metrics':'Accuracy,Precison,Recall','Layers':2})\n",
    "    dl_eval(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf0f1ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_3.save('Models/bilstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72266cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_2.save('Models/lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0823d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
